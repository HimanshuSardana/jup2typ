{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5d5375b-c0aa-46d9-945a-a57b30e13741",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906d6dcd-499d-416e-9a30-4b00e4d75ea8",
   "metadata": {},
   "source": [
    "# Convert a grayscale image to binary image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37807420-f5bf-47ea-babd-980330df6f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./gray.jpeg', cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a88349-a035-436a-90c3-a29013b3c263",
   "metadata": {},
   "source": [
    "### Using mean threhold value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5f63c5ef-fe01-48db-bb22-87e7259ca8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(img)\n",
    "_, binary_img = cv2.threshold(img, mean, 255, cv2.THRESH_BINARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9b4a79e9-31d6-4f31-9f3a-5940f9ec916b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('./binary_image.jpeg', binary_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65566a1-7be7-4384-b479-e9438236cd00",
   "metadata": {},
   "source": [
    "### Using user-defined threshold value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ce2a11c9-14da-48b1-af0d-d0c7a0bebf97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter threshold value:  190\n"
     ]
    }
   ],
   "source": [
    "mean = int(input(\"Enter threshold value: \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c97b3336-5e2e-49ab-b479-8f88257f860d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, binary_img = cv2.threshold(img, mean, 255, cv2.THRESH_BINARY)\n",
    "cv2.imwrite('./binary_image.jpeg', binary_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535cc146-72b2-4050-aff9-5126af1fae9f",
   "metadata": {},
   "source": [
    "# Convert a colored image to grayscale image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e745e4ac-9777-49ed-a94a-d865f4ce1132",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./color.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec28c42-97f7-4d09-b5c0-a2cba9b5c9e2",
   "metadata": {},
   "source": [
    "### By taking mean average of all three planes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1d0f1ce6-b18a-426c-b512-b0af92a56d64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[214, 217, 221, ..., 162, 162, 162],\n",
       "       [215, 217, 219, ..., 162, 162, 161],\n",
       "       [217, 217, 219, ..., 162, 162, 161],\n",
       "       ...,\n",
       "       [184, 184, 184, ..., 197, 197, 197],\n",
       "       [184, 184, 184, ..., 196, 195, 196],\n",
       "       [184, 184, 184, ..., 195, 195, 195]],\n",
       "      shape=(3004, 4103), dtype=uint8)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grayscale = np.mean(img, axis=2)\n",
    "# convert grayscale to unsigned integers (get rid of decimals/floating point numbers)\n",
    "grayscale.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cdd97992-6eaa-4d41-a3db-0e08735520f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('./grayscale.jpg', grayscale)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc3a45c-bd6a-4028-9b10-3341bc64a4c4",
   "metadata": {},
   "source": [
    "### Input weightage from user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0306c7fd-1359-4055-84f4-919dc38f269e",
   "metadata": {},
   "source": [
    "**Weightage** is a value between 0 to 1 and sum of all three weightages is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "bcdf272e-0f22-47f3-b84d-485015d2b345",
   "metadata": {},
   "outputs": [],
   "source": [
    "weightage_r = 0.6\n",
    "weightage_g = 0.0\n",
    "weightage_b = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a5b5ae64-5797-418f-abd8-5e4795b459a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./holi.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ced7fabe-d24a-4d86-9c18-aea2558949ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_img = (weightage_r * img[:, :, 2]) + (weightage_g * img[:, :, 1]) + (weightage_b * img[:, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a01b1c2c-8812-45f2-b00e-dd70364af1a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('./holi_grayscale.jpg', gray_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08eca97d-0b62-4d52-bb04-0087e116acb3",
   "metadata": {},
   "source": [
    "# Draw a border around the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e4a067-e399-4ead-95cf-73076bc6a737",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./gray.jpeg', cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883a2dd5-7940-4505-8e94-f696467b1f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check if image is binary\n",
    "# flattened_values = (set(img.flatten()))\n",
    "# if len(flattened_values) != 2:\n",
    "#     # not a binary image\n",
    "#     img = cv2.threshold(img, np.mean(img), 255, cv2.THRESH_BINARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7921ed41-5fef-4f98-a31f-d7768c9e23e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img)\n",
    "# img = np.array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691e3ca0-1172-470b-b4f9-8b85598ef479",
   "metadata": {},
   "outputs": [],
   "source": [
    "border_width = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e4efb0-6975-4007-8ccd-1345a9ef4421",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_with_border = cv2.copyMakeBorder(img, border_width, border_width, border_width, border_width, cv2.BORDER_CONSTANT, value=(255, 0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e30939-3590-468e-92b5-c8a403b8c7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(\"border_image.jpeg\", img_with_border)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b334e15d-0755-440d-a01c-b87f67c4815d",
   "metadata": {},
   "source": [
    "# Getting complement of image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25d84d92-7b84-47b6-835e-2645b498b367",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./binary_image.jpeg', cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d8d54d4-e48e-4e3c-a0ea-8cd85100f019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complement = 255 - img\n",
    "cv2.imwrite('complement.jpeg', complement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a340bc57-5d44-4f64-a03f-b9b1c2bddb48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

